<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"8.0.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="分布式爬虫将多台主机组合起来，共同完成一个爬取任务 Scrapy-Redis 库提供了 Scrapy 分布式的队列、调度器、去重等功能 14.3 Scrapy 分布式实现利用 Scrapy-Redis 来实现分布式对接 搭建 Redis 服务器要实现分布式部署，多台主机需要共享爬取队列和去重集合，而这两部分内容是存于 Redis 数据库中的，需要搭建一个可公网访问的 Redis 服务器 推荐使用">
<meta property="og:type" content="article">
<meta property="og:title" content="Python3网络爬虫开发实战-分布式爬虫">
<meta property="og:url" content="http://example.com/2022/04/23/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="分布式爬虫将多台主机组合起来，共同完成一个爬取任务 Scrapy-Redis 库提供了 Scrapy 分布式的队列、调度器、去重等功能 14.3 Scrapy 分布式实现利用 Scrapy-Redis 来实现分布式对接 搭建 Redis 服务器要实现分布式部署，多台主机需要共享爬取队列和去重集合，而这两部分内容是存于 Redis 数据库中的，需要搭建一个可公网访问的 Redis 服务器 推荐使用">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-04-23T02:35:41.000Z">
<meta property="article:modified_time" content="2022-04-24T01:30:18.911Z">
<meta property="article:author" content="daxun">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2022/04/23/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Python3网络爬虫开发实战-分布式爬虫 | Hexo</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">简单记录下</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#14-3-Scrapy-%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.</span> <span class="nav-text">14.3 Scrapy 分布式实现</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA-Redis-%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="nav-number">1.1.</span> <span class="nav-text">搭建 Redis 服务器</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Scrapy-Redis"><span class="nav-number">1.2.</span> <span class="nav-text">配置 Scrapy-Redis</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97"><span class="nav-number">1.3.</span> <span class="nav-text">配置调度队列</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">1.4.</span> <span class="nav-text">配置持久化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E9%87%8D%E7%88%AC"><span class="nav-number">1.5.</span> <span class="nav-text">配置重爬</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Pipeline-%E9%85%8D%E7%BD%AE"><span class="nav-number">1.6.</span> <span class="nav-text">Pipeline 配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E5%AD%98%E5%82%A8%E7%9B%AE%E6%A0%87"><span class="nav-number">1.7.</span> <span class="nav-text">配置存储目标</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C"><span class="nav-number">1.8.</span> <span class="nav-text">运行</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-5-Bloom-Filter-%E5%AF%B9%E6%8E%A5"><span class="nav-number">2.</span> <span class="nav-text">14.5 Bloom Filter 对接</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AF%B9%E6%8E%A5-Scrapy-Redis"><span class="nav-number">2.1.</span> <span class="nav-text">对接 Scrapy-Redis</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E9%83%A8%E7%BD%B2"><span class="nav-number">3.</span> <span class="nav-text">分布式爬虫部署</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-1-Scrapyd-%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2"><span class="nav-number">4.</span> <span class="nav-text">15.1 Scrapyd 分布式部署</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyd"><span class="nav-number">4.1.</span> <span class="nav-text">Scrapyd</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyd-API"><span class="nav-number">4.2.</span> <span class="nav-text">Scrapyd API</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-2-Scrapyd-Client"><span class="nav-number">5.</span> <span class="nav-text">15.2 Scrapyd-Client</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyd-Client-%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.</span> <span class="nav-text">Scrapyd-Client 部署</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-3-Scrapyd-%E5%AF%B9%E6%8E%A5-Docker"><span class="nav-number">6.</span> <span class="nav-text">15.3 Scrapyd 对接 Docker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-4-Scrapyd-%E6%89%B9%E9%87%8F%E9%83%A8%E7%BD%B2"><span class="nav-number">7.</span> <span class="nav-text">15.4 Scrapyd 批量部署</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">daxun</p>
  <div class="site-description" itemprop="description">简单记录下</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">93</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/23/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="daxun">
      <meta itemprop="description" content="简单记录下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python3网络爬虫开发实战-分布式爬虫
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-23 10:35:41" itemprop="dateCreated datePublished" datetime="2022-04-23T10:35:41+08:00">2022-04-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-04-24 09:30:18" itemprop="dateModified" datetime="2022-04-24T09:30:18+08:00">2022-04-24</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>分布式爬虫将多台主机组合起来，共同完成一个爬取任务</p>
<p>Scrapy-Redis 库提供了 Scrapy 分布式的队列、调度器、去重等功能</p>
<h4 id="14-3-Scrapy-分布式实现"><a href="#14-3-Scrapy-分布式实现" class="headerlink" title="14.3 Scrapy 分布式实现"></a>14.3 Scrapy 分布式实现</h4><p>利用 Scrapy-Redis 来实现分布式对接</p>
<h5 id="搭建-Redis-服务器"><a href="#搭建-Redis-服务器" class="headerlink" title="搭建 Redis 服务器"></a>搭建 Redis 服务器</h5><p>要实现分布式部署，多台主机需要共享爬取队列和去重集合，而这两部分内容是存于 Redis 数据库中的，需要搭建一个可公网访问的 Redis 服务器</p>
<p>推荐使用 Linux 服务器，可以购买阿里云、腾讯云、Azure等提供的云主机，一般都会配有公网 IP</p>
<p>阿里云、腾讯云的服务器需要配置安全组放通 Redis 运行端口才可以远程访问</p>
<h5 id="配置-Scrapy-Redis"><a href="#配置-Scrapy-Redis" class="headerlink" title="配置 Scrapy-Redis"></a>配置 Scrapy-Redis</h5><ul>
<li>核心配置</li>
</ul>
<p>将调度器的类和去重的类替换为 Scrapy-Redis 提供的类，settings.py 里添加配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SCHEDULER &#x3D; &quot;scrapy_redis.scheduler.Scheduler&quot;</span><br><span class="line">DUPEFILTER_CLASS &#x3D; &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span><br></pre></td></tr></table></figure>

<ul>
<li>Redis 连接配置</li>
</ul>
<p>方式一：通过连接字符串配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis://[:password]@host:port/db</span><br><span class="line">rediss://[:password]@host:port/db</span><br><span class="line">unix://[:password]@/path/to/socket.sock?db=db</span><br><span class="line"><span class="comment">#如 redis://:foobared@127.2.34.25:6379</span></span><br></pre></td></tr></table></figure>

<p>中括号代表此选项可有可无 db是数据库代号，默认值 0</p>
<p>settings.py 里配置为 REDIS_URL 变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REDIS_URL &#x3D; &#39;redis:&#x2F;&#x2F;:foobared@127.2.34.25:6379&#39;</span><br></pre></td></tr></table></figure>

<p>方式二：是分项单独配置， settings.py 中配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">REDIS_HOST &#x3D; &#39;127.2.34.25&#39;</span><br><span class="line">REDIS_PORT &#x3D; &#39;6379&#39;</span><br><span class="line">REDIS_PASSWORD &#x3D; &#39;foobared&#39;</span><br></pre></td></tr></table></figure>

<h5 id="配置调度队列"><a href="#配置调度队列" class="headerlink" title="配置调度队列"></a>配置调度队列</h5><p>此配置可选，默认使用 PriorityQueue，如果想更改配置，可有配置 SCHEDULER_QUEUE_CLASS 变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SCHEDULER_QUEUE_CLASS &#x3D; &#39;scrapy_redis.queue.PriorityQueue&#39;</span><br><span class="line">SCHEDULER_QUEUE_CLASS &#x3D; &#39;scrapy_redis.queue.FifoQueue&#39;</span><br><span class="line">SCHEDULER_QUEUE_CLASS &#x3D; &#39;scrapy_redis.queue.LifoQueue&#39;</span><br></pre></td></tr></table></figure>

<p>任选一配置，即可切换爬取队列的存储方式</p>
<h5 id="配置持久化"><a href="#配置持久化" class="headerlink" title="配置持久化"></a>配置持久化</h5><p>可选配置，默认 False。Scrapy-Redis 默认会在爬取全部完成清空爬取队列和去重指纹集合</p>
<p>如果不想自动清空爬取队列和去重指纹集合，可以增加配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SCHEDULER_PERSIST &#x3D; True</span><br></pre></td></tr></table></figure>

<h5 id="配置重爬"><a href="#配置重爬" class="headerlink" title="配置重爬"></a>配置重爬</h5><p>可选配置，默认 False，如果配置了持久化或者强制中断了爬虫，那么爬取队列和指纹集合不会被清空，爬虫重启之后就会接上次爬取，如果想重新爬取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SCHEDULER_FLUSH_ON_START &#x3D; True</span><br></pre></td></tr></table></figure>

<p>分布式爬取不常用此配置</p>
<h5 id="Pipeline-配置"><a href="#Pipeline-配置" class="headerlink" title="Pipeline 配置"></a>Pipeline 配置</h5><p>可选配置，默认不启动</p>
<h5 id="配置存储目标"><a href="#配置存储目标" class="headerlink" title="配置存储目标"></a>配置存储目标</h5><p>最好将存储目标存到同一地方，可以在服务器上搭建一个 MongoDB 服务，或者购买 MongoDB 数据存储服务</p>
<p>这里使用服务器上搭建的 MongoDB 服务 ，IP120.27.34.25 用户名 admin 密码 admin123</p>
<p>修改 MONGO_URI </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MONGO_URI &#x3D; &#39;mongodb:&#x2F;&#x2F;admin:admin123@120.27.34.25:27017&#39;</span><br></pre></td></tr></table></figure>

<h5 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl weibocn</span><br></pre></td></tr></table></figure>

<p>每台主机启动了此命令之后，就会从配置的 Redis 数据库中调度 Request，做到爬取队列共享和指纹集合共享，每台主机占用各自的宽带和处理器，不会互相影响</p>
<h4 id="14-5-Bloom-Filter-对接"><a href="#14-5-Bloom-Filter-对接" class="headerlink" title="14.5 Bloom Filter 对接"></a>14.5 Bloom Filter 对接</h4><p>布隆过滤器，用来检测一个元素是否在一个集合中</p>
<h5 id="对接-Scrapy-Redis"><a href="#对接-Scrapy-Redis" class="headerlink" title="对接 Scrapy-Redis"></a>对接 Scrapy-Redis</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install scrapy-redis-bloomfilter</span><br></pre></td></tr></table></figure>

<p>配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#去重类，要使用Bloom Filter 替换 DUPEFILTER_CLASS</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&#x27;scrapy_redis_bloomfilter.dupefilter.RFPDupeFilter&#x27;</span></span><br><span class="line"><span class="comment">#散列函数的个数 默认 6</span></span><br><span class="line">BLOOMFILTER_HASH_NUMBER = <span class="number">6</span></span><br><span class="line"><span class="comment">#Bloom Filter 的bit参数 默认30 占用128M空间，去重量级1亿</span></span><br><span class="line">BLOOMFILTER_BIT = <span class="number">30</span></span><br></pre></td></tr></table></figure>



<h4 id="分布式爬虫部署"><a href="#分布式爬虫部署" class="headerlink" title="分布式爬虫部署"></a>分布式爬虫部署</h4><h4 id="15-1-Scrapyd-分布式部署"><a href="#15-1-Scrapyd-分布式部署" class="headerlink" title="15.1 Scrapyd 分布式部署"></a>15.1 Scrapyd 分布式部署</h4><p>Scrapyd 运行 Scrapy 爬虫的服务程序，提供一系列 HTTP 接口帮助部署、启动、停止、删除爬虫程序</p>
<h5 id="Scrapyd"><a href="#Scrapyd" class="headerlink" title="Scrapyd"></a>Scrapyd</h5><h5 id="Scrapyd-API"><a href="#Scrapyd-API" class="headerlink" title="Scrapyd API"></a>Scrapyd API</h5><h4 id="15-2-Scrapyd-Client"><a href="#15-2-Scrapyd-Client" class="headerlink" title="15.2 Scrapyd-Client"></a>15.2 Scrapyd-Client</h4><p>Scrapyd-Client 为了方便 Scrapy 项目的部署，提供了两个功能</p>
<p>将项目打包成 Egg文件</p>
<p>将打包生成的Egg文件通过 addversion.json 接口部署到 Scrapyd 上</p>
<h5 id="Scrapyd-Client-部署"><a href="#Scrapyd-Client-部署" class="headerlink" title="Scrapyd-Client 部署"></a>Scrapyd-Client 部署</h5><h4 id="15-3-Scrapyd-对接-Docker"><a href="#15-3-Scrapyd-对接-Docker" class="headerlink" title="15.3 Scrapyd 对接 Docker"></a>15.3 Scrapyd 对接 Docker</h4><p>将 Scrapyd 打包成一个 Docker 镜像，那么在服务器上只需要执行 Docker 命令就可以启动 Scrapyd 服务，就不用关心 Python 环境问题，也不需要担心版本冲突问题</p>
<h4 id="15-4-Scrapyd-批量部署"><a href="#15-4-Scrapyd-批量部署" class="headerlink" title="15.4 Scrapyd 批量部署"></a>15.4 Scrapyd 批量部署</h4>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/04/21/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-9%E4%BB%A3%E7%90%86%E7%9A%84%E4%BD%BF%E7%94%A8/" rel="prev" title="Python3网络爬虫开发实战-9代理的使用">
                  <i class="fa fa-chevron-left"></i> Python3网络爬虫开发实战-9代理的使用
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/04/25/%E8%AE%B0%E5%BD%95%E4%B8%8B1/" rel="next" title="记录下1">
                  记录下1 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">daxun</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/local-search.js"></script>















  








  

  

</body>
</html>
