<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"8.0.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="urllib、request 3. 基本库使用3.1 urllibPython内置 HTTP 请求库，包含4个模块  request  基本 HTTP 请求模块，用来模拟发送请求  error  异常处理，如果出现请求错误，可以捕获这些异常  parse  工具模块，提供了许多 URL 处理方法 如拆分、解析、合并  robotparser  识别网站 robots.txt 文件，然后判断哪些网站">
<meta property="og:type" content="article">
<meta property="og:title" content="Python3网络爬虫开发实战-基本库使用">
<meta property="og:url" content="http://example.com/2022/04/11/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E5%9F%BA%E6%9C%AC%E5%BA%93%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="urllib、request 3. 基本库使用3.1 urllibPython内置 HTTP 请求库，包含4个模块  request  基本 HTTP 请求模块，用来模拟发送请求  error  异常处理，如果出现请求错误，可以捕获这些异常  parse  工具模块，提供了许多 URL 处理方法 如拆分、解析、合并  robotparser  识别网站 robots.txt 文件，然后判断哪些网站">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-04-11T08:35:56.000Z">
<meta property="article:modified_time" content="2022-04-13T13:10:26.681Z">
<meta property="article:author" content="daxun">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2022/04/11/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E5%9F%BA%E6%9C%AC%E5%BA%93%E4%BD%BF%E7%94%A8/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Python3网络爬虫开发实战-基本库使用 | Hexo</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">简单记录下</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%9F%BA%E6%9C%AC%E5%BA%93%E4%BD%BF%E7%94%A8"><span class="nav-number">1.</span> <span class="nav-text">3. 基本库使用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-urllib"><span class="nav-number">1.1.</span> <span class="nav-text">3.1 urllib</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#3-1-1-%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82"><span class="nav-number">1.1.1.</span> <span class="nav-text">3.1.1 发送请求</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-1-2-%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8"><span class="nav-number">1.1.2.</span> <span class="nav-text">3.1.2 处理异常</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-1-3-%E8%A7%A3%E6%9E%90%E9%93%BE%E6%8E%A5"><span class="nav-number">1.1.3.</span> <span class="nav-text">3.1.3 解析链接</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-1-4-%E5%88%86%E6%9E%90-Robots-%E5%8D%8F%E8%AE%AE"><span class="nav-number">1.1.4.</span> <span class="nav-text">3.1.4 分析 Robots 协议</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-%E4%BD%BF%E7%94%A8-Request"><span class="nav-number">1.2.</span> <span class="nav-text">3.2 使用 Request</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#3-2-1-%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95"><span class="nav-number">1.2.1.</span> <span class="nav-text">3.2.1 基本用法</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-2-2-%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95"><span class="nav-number">1.2.2.</span> <span class="nav-text">3.2.2 高级用法</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-3-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">1.3.</span> <span class="nav-text">3.3 正则表达式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-4-%E6%8A%93%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1%E6%8E%92%E8%A1%8C"><span class="nav-number">1.4.</span> <span class="nav-text">3.4 抓取猫眼电影排行</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text"></span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">daxun</p>
  <div class="site-description" itemprop="description">简单记录下</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/11/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E5%9F%BA%E6%9C%AC%E5%BA%93%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="daxun">
      <meta itemprop="description" content="简单记录下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python3网络爬虫开发实战-基本库使用
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-11 16:35:56" itemprop="dateCreated datePublished" datetime="2022-04-11T16:35:56+08:00">2022-04-11</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-04-13 21:10:26" itemprop="dateModified" datetime="2022-04-13T21:10:26+08:00">2022-04-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>urllib、request</p>
<h4 id="3-基本库使用"><a href="#3-基本库使用" class="headerlink" title="3. 基本库使用"></a>3. 基本库使用</h4><h5 id="3-1-urllib"><a href="#3-1-urllib" class="headerlink" title="3.1 urllib"></a>3.1 urllib</h5><p>Python内置 HTTP 请求库，包含4个模块</p>
<ul>
<li>request</li>
</ul>
<p>基本 HTTP 请求模块，用来模拟发送请求</p>
<ul>
<li>error</li>
</ul>
<p>异常处理，如果出现请求错误，可以捕获这些异常</p>
<ul>
<li>parse</li>
</ul>
<p>工具模块，提供了许多 URL 处理方法 如拆分、解析、合并</p>
<ul>
<li>robotparser</li>
</ul>
<p>识别网站 robots.txt 文件，然后判断哪些网站可以爬，实际用的少</p>
<h6 id="3-1-1-发送请求"><a href="#3-1-1-发送请求" class="headerlink" title="3.1.1 发送请求"></a>3.1.1 发送请求</h6><ol>
<li>urlopen() </li>
</ol>
<p>可以完成简单请求和网页抓取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> http.client <span class="keyword">import</span> HTTPResponse</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.python.org&#x27;</span>) <span class="comment">#type: HTTPResponse</span></span><br><span class="line">print(<span class="built_in">type</span>(response)) //&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">http</span>.<span class="title">client</span>.<span class="title">HTTPResponse</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">print</span>(<span class="params">response.read(<span class="params"></span>).decode(<span class="params"><span class="string">&#x27;utf-8&#x27;</span></span>)</span>)</span></span><br><span class="line"><span class="class"><span class="title">print</span>(<span class="params">response.status</span>)</span></span><br><span class="line"><span class="class"><span class="title">print</span>(<span class="params">response.getheaders(<span class="params"></span>)</span>)</span></span><br><span class="line"><span class="class"><span class="title">print</span>(<span class="params">response.getheader(<span class="params"><span class="string">&#x27;Server&#x27;</span></span>)</span>)</span></span><br></pre></td></tr></table></figure>

<p>调用 read 方法可以得到返回的网页内容</p>
<blockquote>
<p>response 敲属性代码没提示，加上类型注释 #type: HTTPResponse</p>
<p>或者使用 isinstance 指定 assert isinstance(response, HTTPResponse)</p>
</blockquote>
<p>urlopen 的参数 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urlopen(url, data=<span class="literal">None</span>, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>data参数： 可选，如果是字节流编码格式内容，即 bytes 类型，需要通过 bytes() 方法转换，如果传递了参数则是 POST 方式请求</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> http.client <span class="keyword">import</span> HTTPResponse</span><br><span class="line"></span><br><span class="line">data = <span class="built_in">bytes</span>(urllib.parse.urlencode(&#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;hello&#x27;</span>&#125;),encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=data) <span class="comment">#type: HTTPResponse</span></span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure>

<p>byte() 方法第一个参数需要 str 类型，需要用 urllib.parse 模块里的 urlencode() 方法将参数字典转化为字符串</p>
<p>站点 <a target="_blank" rel="noopener" href="http://httpbin.org/post">http://httpbin.org/post</a>  可以提供 HTTP 请求测试</p>
<p>timeout参数： 超时时间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"><span class="keyword">from</span> http.client <span class="keyword">import</span> HTTPResponse</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, timeout=<span class="number">0.1</span>)<span class="comment">#type: HTTPResponse</span></span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(e.reason, socket.timeout):</span><br><span class="line">        print(<span class="string">&#x27;TIME OUT&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>其它参数</li>
</ul>
<p>context 参数：必须是 ssl.SSLContext 类型，用来指定 SSL 设置</p>
<p>cafile 和 capath ：分别指定 CA 证书 和 它的路径，这个在请求 HTTPS 链接时会有用</p>
<ol start="2">
<li>Request</li>
</ol>
<p>如果需要 Headers 等信息，可以利用更加强大的 Resquest 类来构建</p>
<p>利用 Request 可以将请求独立成一个对象，更加丰富的配置参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> http.client <span class="keyword">import</span> HTTPResponse</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(<span class="string">&#x27;https://python.org&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(request) <span class="comment">#type: HTTPResponse</span></span><br><span class="line">print(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>Request 参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url, data=<span class="literal">None</span>, headers=&#123;&#125;,origin_req_host=<span class="literal">None</span>, unverifiable=<span class="literal">False</span>,method=<span class="literal">None</span></span><br></pre></td></tr></table></figure>

<p>url：必传参数，其它都是可选</p>
<p>data：如果要传，必须传 bytes（字节流）类型的，如果它是字典，先用 urllib.parse 模块里的 urlenode() 编码</p>
<p>headers： 是一个字典，可以在构建请求时通过 headers 直接构建，也可通过调用请求实例的 add_header()方法添加，可以通过修改 User-Agent 来伪装浏览器，默认是 Python-urllib</p>
<p>origin_req_host：请求方 host 名称或 IP 地址</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> http.client <span class="keyword">import</span> HTTPResponse</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/post&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/4.0 (compatible)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;httpbin.org&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">dict</span> = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Germey&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data = <span class="built_in">bytes</span>(urllib.parse.urlencode(<span class="built_in">dict</span>), encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">req = request.Request(url=url, data=data, headers=headers, method=<span class="string">&#x27;POST&#x27;</span>)</span><br><span class="line">response = request.urlopen(req)</span><br><span class="line"><span class="comment"># type:HTTPResponse</span></span><br><span class="line">print(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))&#125;</span><br></pre></td></tr></table></figure>

<p>unverifiable：这个请求是否是无法验证的，默认 false，</p>
<p>method：请求方法 POST GET</p>
<p>headers 也可以用 add_header() 方法添加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">req = request.Request(url=url, data=data, method=<span class="string">&#x27;POST&#x27;</span>)</span><br><span class="line">req.add_header(<span class="string">&#x27;User-Agent&#x27;</span>, <span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>高级用法</li>
</ol>
<p>更高级的操作（Cookie处理、设置代理）该怎么操作？使用 Handler，可以理解为各种处理器</p>
<p>urllib.request 模块里的 BaseHandler 类是所有 Handler 的父类</p>
<p>子类：</p>
<p>HTTPDefaultErrorHandler：处理 HTTP 响应错误，错误会抛出 HTTPError 类型异常</p>
<p>HTTPRedirectHandler：用于处理重定向</p>
<p>HTTPCookieProcessor：用于处理 Cookies</p>
<p>ProxyHandler：用于设置代理</p>
<p>HTTPPasswordMgr：用于管理密码</p>
<p>HTTPBasicAuthHandler：用于管理认证，如果一个链接打开时需要认证，可以用它来解决认证问题</p>
<p>OpenerDirector：可以称为 Opener，可以利用 Handler 来构建 Opener</p>
<p>用法：登录验证、代理、Cookie</p>
<h6 id="3-1-2-处理异常"><a href="#3-1-2-处理异常" class="headerlink" title="3.1.2 处理异常"></a>3.1.2 处理异常</h6><ol>
<li>URLError</li>
</ol>
<p>由 request 模块生成的异常都可以通过捕获这个类来处理，有一个 reason 属性，返回错误的原因</p>
<p>例子：打开一个不存在的页面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">&#x27;https://cuiqingcai.com/index.htm&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>HTTPError</li>
</ol>
<p>URLError 的子类，专门用来处理 HTTP 请求错误，比如认证失败，有3个属性，code，reason，headers</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.code, e.reason, e.headers, seq=<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>URLError 是 HTTPError 的父类，所以先捕获子类错误再捕获父类错误</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.code, e.reason, e.headers, seq=<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&#x27;success&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>reason 返回的不一定是字符串，也可能是一个对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line">...</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">  print(<span class="built_in">type</span>(e.reason))</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(e.reason, socket.timeout):</span><br><span class="line">    print(<span class="string">&#x27;TIME OUT&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h6 id="3-1-3-解析链接"><a href="#3-1-3-解析链接" class="headerlink" title="3.1.3 解析链接"></a>3.1.3 解析链接</h6><p>urllib 库还提供了 parse 模块，定义了处理 URL 的标准接口，例如实现 URL 各部分的抽取、合并及链接转换</p>
<ol>
<li>urlparse()</li>
</ol>
<p>实现 URL 的识别和分段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line">result = urlparse(<span class="string">&#x27;http://www.baidu.com/index.html;user?id=s#comment&#x27;</span>)</span><br><span class="line">print(<span class="built_in">type</span>(result), result)</span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">urllib</span>.<span class="title">parse</span>.<span class="title">ParseResult</span>&#x27;&gt; </span></span><br><span class="line"><span class="class"><span class="title">ParseResult</span>(<span class="params">scheme=<span class="string">&#x27;http&#x27;</span>, netloc=<span class="string">&#x27;www.baidu.com&#x27;</span>, path=<span class="string">&#x27;/index.html&#x27;</span>, params=<span class="string">&#x27;user&#x27;</span>, query=<span class="string">&#x27;id=s&#x27;</span>, fragment=<span class="string">&#x27;comment&#x27;</span></span>)</span></span><br></pre></td></tr></table></figure>

<p>输出结果是 ParseResult 类型，包含 6 个部分，scheme、netloc、path、params、query、fragment</p>
<p>可以用索引顺序来获取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(result.scheme, result[<span class="number">0</span>], result.netloc, result[<span class="number">1</span>], sep=<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><code>#</code> 后面是锚点，用于直接定位页面内部的下拉位置</p>
<p>urlparse() 有3个参数：urlstring、scheme、allow_fragments</p>
<p>scheme：http或https等 urlstring中不包含 scheme 信息时才生效</p>
<p>allow_fragments：如果被设置为 false，fragment 部分就会被忽略</p>
<ol start="2">
<li>urlunparse()</li>
</ol>
<p>参数是一个可迭代对象，长度必须是6，构造URL</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse</span><br><span class="line">data = [<span class="string">&#x27;http&#x27;</span>,<span class="string">&#x27;www.baidu.com&#x27;</span>,<span class="string">&#x27;index.html&#x27;</span>,<span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;a=6&#x27;</span>,<span class="string">&#x27;comment&#x27;</span>]</span><br><span class="line">print(urlunparse(data))</span><br><span class="line"><span class="comment">#结果</span></span><br><span class="line">http://www.baidu.com/index.html;user?a=6#comment</span><br><span class="line"><span class="comment">#这里data用了列表类型，也可以用其它类型比如元组或者特定的数据结构</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>urlsplit()</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlsplit</span><br><span class="line">result = urlsplit(<span class="string">&#x27;http://www.baidu.com/index.html;user?id=s#comment&#x27;</span>)</span><br><span class="line">print(<span class="built_in">type</span>(result), result)</span><br></pre></td></tr></table></figure>

<p>和 urlparse 使用类似，不过不再单独解析 params 部分，只返回 5个 结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">urllib</span>.<span class="title">parse</span>.<span class="title">SplitResult</span>&#x27;&gt; <span class="title">SplitResult</span>(<span class="params">scheme=<span class="string">&#x27;http&#x27;</span>, netloc=<span class="string">&#x27;www.baidu.com&#x27;</span>, path=<span class="string">&#x27;/index.html;user&#x27;</span>, query=<span class="string">&#x27;id=s&#x27;</span>, fragment=<span class="string">&#x27;comment&#x27;</span></span>)</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>urlunsplit()</li>
</ol>
<p>将链接各个部分组合成完成链接，传入参数是一个可迭代对象，如列表、元组，长度必须是5</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunsplit</span><br><span class="line">data = [<span class="string">&#x27;http&#x27;</span>,<span class="string">&#x27;www.baidu.com&#x27;</span>,<span class="string">&#x27;index.html&#x27;</span>,<span class="string">&#x27;a=6&#x27;</span>,<span class="string">&#x27;comment&#x27;</span>]</span><br><span class="line">print(urlunsplit(data))</span><br><span class="line"><span class="comment">#http://www.baidu.com/index.html?a=6#comment</span></span><br></pre></td></tr></table></figure>



<ol start="5">
<li>urljoin()</li>
</ol>
<p>urlunparse 和 urlunsplit 我们可以完成链接的合并，不过必须有特定的长度，链接的每一部分都要清晰的分开</p>
<p>生成链接还有个方法 urljoin() 方法</p>
<p>可以提供一个 base_url 基础链接作为第一个参数，将新的链接作为第二个参数</p>
<p>该方法会分析 base_url 的 scheme、netloc、和path 这3个内容对新链接缺失的部分进行补充</p>
<p>实现连接拼合与生成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"></span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, <span class="string">&#x27;FAQ.html&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, <span class="string">&#x27;https://cuiqingcai.com/FAQ.html&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com/about.html&#x27;</span>, <span class="string">&#x27;https://cuiqingcai.com/FAQ.html&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com/about.html&#x27;</span>, <span class="string">&#x27;https://cuiqingcai.com/FAQ.html?question=2&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com?wd=abc&#x27;</span>, <span class="string">&#x27;https://cuiqingcai.com/index.php&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, <span class="string">&#x27;?category=2#comment&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;www.baidu.com&#x27;</span>, <span class="string">&#x27;?category=2#comment&#x27;</span>))</span><br><span class="line">print(urljoin(<span class="string">&#x27;www.baidu.com#comment&#x27;</span>, <span class="string">&#x27;?category=2&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com/FAQ.html</span><br><span class="line">https://cuiqingcai.com/FAQ.html</span><br><span class="line">https://cuiqingcai.com/FAQ.html</span><br><span class="line">https://cuiqingcai.com/FAQ.html?question=2</span><br><span class="line">https://cuiqingcai.com/index.php</span><br><span class="line">http://www.baidu.com?category=2#comment</span><br><span class="line">www.baidu.com?category=2#comment</span><br><span class="line">www.baidu.com?category=2</span><br></pre></td></tr></table></figure>

<p>base_url 提供了三项内容 scheme、netloc、path</p>
<p>如果3项在新链接不存在就补充，新链接存在就使用新链接部分，base_url 里的就不起作用了，以右边新链接为准</p>
<ol start="6">
<li>urlencode()</li>
</ol>
<p>将字典序列化为 GET 请求参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;age&#x27;</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">base_url = <span class="string">&#x27;http://www.baidu.com?&#x27;</span></span><br><span class="line">url = base_url + urlencode(params)</span><br><span class="line">print(url)</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>parse_qs()</li>
</ol>
<p>将请求参数反序列化成字典类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> parse_qs</span><br><span class="line">query = <span class="string">&#x27;name=germey&amp;age=22&#x27;</span></span><br><span class="line">print(parse_qs(query))</span><br><span class="line"><span class="comment">#结果 &#123;&#x27;name&#x27;:[&#x27;germey&#x27;],&#x27;age&#x27;:[&#x27;22&#x27;]&#125;</span></span><br></pre></td></tr></table></figure>



<ol start="7">
<li>parse_sql()</li>
</ol>
<p>将参数转化成元组组成的列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> parse_qsl</span><br><span class="line">query = <span class="string">&#x27;name=germey&amp;age=2&#x27;</span></span><br><span class="line">print(parse_qsl(query))</span><br><span class="line"><span class="comment">#结果 [(&#x27;name&#x27;, &#x27;germey&#x27;), (&#x27;age&#x27;, &#x27;2&#x27;)]</span></span><br></pre></td></tr></table></figure>

<ol start="8">
<li>quote()</li>
</ol>
<p>将内容转化为 URL 编码格式，URL 中带中文参数时，可能导致乱码问题，用这个可以将中文字符转化为 URL 编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line">keyword = <span class="string">&#x27;测试&#x27;</span></span><br><span class="line">url = <span class="string">&#x27;https://baidu.com/s?wd=&#x27;</span> + quote(keyword)</span><br><span class="line"><span class="comment">#结果：https://baidu.com/s?wd=%E5%joj</span></span><br></pre></td></tr></table></figure>

<ol start="9">
<li>unquote()</li>
</ol>
<p>可以进行 URL 解码</p>
<h6 id="3-1-4-分析-Robots-协议"><a href="#3-1-4-分析-Robots-协议" class="headerlink" title="3.1.4 分析 Robots 协议"></a>3.1.4 分析 Robots 协议</h6><p>urllib 的 robotparser 模块，可以实现网站 Robots 协议的分析</p>
<ol>
<li>Robots 协议</li>
</ol>
<p>爬虫协议，全名叫网络爬虫排除标准，告诉爬虫和搜索引擎哪些页面可以抓取不抓取，通常是一个 robots.txt 协议</p>
<ol start="2">
<li>robotparser</li>
</ol>
<p>了解 Robots 协议之后，就可以使用 robotparse 模块来解析 robots.txt 了，该模块提供了一个类 RobotFileParse，它可以根据某网站的 robots.txt 文件来判断一个爬虫是否有权限来爬取这个网页</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.robotparser <span class="keyword">import</span> RobotFileParser</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"></span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line">rp = RobotFileParser()</span><br><span class="line">rp.set_url(<span class="string">&#x27;https://www.jianshu.com/robots.txt&#x27;</span>)</span><br><span class="line">rp.read()</span><br><span class="line"><span class="comment">#判断网页是否可以被抓取</span></span><br><span class="line">print(rp.can_fetch(<span class="string">&#x27;*&#x27;</span>, <span class="string">&#x27;https://www.jianshu.com/p/823596514412&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>常用几个方法：</p>
<p>set_url()：设置 robots.txt 文件的链接</p>
<p>read()：读取 robots.txt 文件并进行分享，不会返回任何内容，但执行了读取操作</p>
<p>parse()：用来解析 robots.txt 文件，传入的参数是 robots.txt 某些行的内容</p>
<p>can_fetch()：两个参数，第一个 User-agent，第二个要抓取的URL，返回该搜索引擎是否可以抓取这个URL</p>
<p>mtime()：返回上次抓取和分析 robots.txt 时间</p>
<h5 id="3-2-使用-Request"><a href="#3-2-使用-Request" class="headerlink" title="3.2 使用 Request"></a>3.2 使用 Request</h5><h6 id="3-2-1-基本用法"><a href="#3-2-1-基本用法" class="headerlink" title="3.2.1 基本用法"></a>3.2.1 基本用法</h6><ul>
<li>GET 请求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.baidu.com/&#x27;</span>)</span><br><span class="line">print(<span class="built_in">type</span>(r))</span><br><span class="line">print(r.status_code)</span><br><span class="line">print(<span class="built_in">type</span>(r.text))</span><br><span class="line">print(r.text)</span><br><span class="line">print(r.cookies)</span><br></pre></td></tr></table></figure>

<p>调用 get() 方法实现与 urlopen 相同的操作，得到一个 Response 对象</p>
<p>带参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  requests</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;germey&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;age&#x27;</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, params=params)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<p>网页的返回类型实际上是 str 类型，JSON格式的，想得到字典格式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(r.json())</span><br></pre></td></tr></table></figure>

<p>如果返回结果不是 JSON 格式，会出现解析错误，抛出 json.decoder.JSONDecodeError 异常</p>
<ul>
<li>抓取二进制数据</li>
</ul>
<p>图片、音频、视频这些文件本质上都是二进制码组成</p>
<p>提取图片保存下来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://github.com/favicon.ico&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;vavicon.ico&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f: <span class="comment">#wb写入</span></span><br><span class="line">    f.write(r.content)</span><br><span class="line"><span class="comment">#调用了open方法，第一个参数文件名，第二个参数代表以二进制写的形式打开，可以向文件写入二进制数据</span></span><br></pre></td></tr></table></figure>

<ul>
<li> POST 请求</li>
</ul>
<h6 id="3-2-2-高级用法"><a href="#3-2-2-高级用法" class="headerlink" title="3.2.2 高级用法"></a>3.2.2 高级用法</h6><ol>
<li>文件上传</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">files = &#123;<span class="string">&#x27;file&#x27;</span>: <span class="built_in">open</span>(<span class="string">&#x27;favicon.ico&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>)&#125; <span class="comment">#rb读取</span></span><br><span class="line">r = requests.post(<span class="string">&#x27;https://httpbin.org/post&#x27;</span>, files=files)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Cookies</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">print(r.cookies)<span class="comment">#RequestsCookieJar</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">    print(key+<span class="string">&#x27;=&#x27;</span>+value)</span><br></pre></td></tr></table></figure>

<p>模拟Cookies，放 headers里面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">	<span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">  <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">r = request.get(<span class="string">&#x27;https://xxxx&#x27;</span>, headers=headers)</span><br></pre></td></tr></table></figure>

<p>也可以通过 cookies 参数来设置，不过需要构建 RequestsCookieJar对象，然后复制下来的 cookies 利用 split 方法分割，再利用 set 方法设置好每个 Cookie 的 key 和 value</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cookies = <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">jar = requests.cookies.RequestsCookieJar()</span><br><span class="line"><span class="keyword">for</span> cookies <span class="keyword">in</span> cookies.split(<span class="string">&#x27;;&#x27;</span>):</span><br><span class="line">  key, value = cookie.split(<span class="string">&#x27;=&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">  jar.<span class="built_in">set</span>(key, value)</span><br><span class="line">r = request.get(<span class="string">&#x27;https://xxxx&#x27;</span>, cookies=jar)</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>会话维持</li>
</ol>
<p>方便维持一个会话，不用担心 cookies 问题</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">requests.get(<span class="string">&#x27;http://httpbin.org/cookies/set/number/123456&#x27;</span>)<span class="comment">#请求这个网址时可以设置一个cookie</span></span><br><span class="line">r = requests.get(<span class="string">&#x27;http://httpbin.org/cookies&#x27;</span>)</span><br><span class="line">print(r.text)</span><br><span class="line"><span class="comment">#结果&#123;&quot;cookies&quot;: &#123;&#125;&#125;</span></span><br></pre></td></tr></table></figure>

<p>上面是两个不相关的会话，第一个设置了 cookies，第二个 cookies 为空</p>
<p>使用 session</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = requests.session()</span><br><span class="line">s.get(<span class="string">&#x27;http://httpbin.org/cookies/set/number/123456&#x27;</span>)</span><br><span class="line">r = s.get(<span class="string">&#x27;http://httpbin.org/cookies&#x27;</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<p>成功获取，两个请求在同一会话，不用担心 cookies 问题</p>
<p>通常用于模拟登录成功之后再进行下一步的操作</p>
<ol start="4">
<li>SSL 证书验证</li>
</ol>
<p>请求一个 HTTPS 站点，但证书验证错误的页面，会报 SSLError 错误，如何避免这个错误？</p>
<p>request 提供了证书验证的功能，使用 verify 参数控制是否检查证书</p>
<p>将 verify 参数设置为 False 即可</p>
<p>当然也可以指定本地证书用作客户端证书，这可以是单个文件（包含秘钥和证书）或一个包含两个文件路径的元组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(<span class="string">&#x27;https://www.12306.cn&#x27;</span>, cert=(<span class="string">&#x27;/path/server.crt&#x27;</span>, <span class="string">&#x27;/path/key&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>上面的例子，我们需要有 crt 和 key 文件，且指定路径。本地私有证书的key必须是解密状态</p>
<ol start="5">
<li>代理设置</li>
</ol>
<p>某些网站测试请求几次能正常获取，一旦大规模爬取，网站可能会弹出验证码或跳转登录页面内</p>
<p>用代理来解决这个问题，就要用到 proxies 参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies = &#123;</span><br><span class="line">  <span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://10.10.1.10:3128&quot;</span>,</span><br><span class="line">  <span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://10.10.1.10:1080&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">request.get(<span class="string">&quot;https://www.taobao.com&quot;</span>, proxiex=proxies)</span><br></pre></td></tr></table></figure>

<p>若代理需要使用 HTTP Basic Auth，可以使用类似 <a href="http://user:pasword@host:port">http://user:pasword@host:port</a> 这样的语法来设置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">proxiex = &#123;</span><br><span class="line">	<span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://user:password@10.10.1.10:3128&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>除了 HTTP 代理外，request 还支持 SOCKS 协议的代理</p>
<p>需要安装 socks 这个库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install <span class="string">&#x27;requests[socks]&#x27;</span></span><br></pre></td></tr></table></figure>



<ol start="6">
<li>超时设置</li>
</ol>
<p>timeout 参数</p>
<ol start="7">
<li>身份认证</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line">r = requests.get(<span class="string">&#x27;http://xxx&#x27;</span>, auth=HTTPBasicAuth(<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;password&#x27;</span>))</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>

<p>如果用户名和密码正确，请求会自动认证成功返回200，错误401</p>
<p>也可以传一个元组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;http://xxx&#x27;</span>, auth=(<span class="string">&#x27;username&#x27;</span>,<span class="string">&#x27;password&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>还提供了其它认证方式，如 OAuth，需要安装 oauth 包</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install requests_oauthlib</span><br></pre></td></tr></table></figure>





<ol start="8">
<li>Prepared Request</li>
</ol>
<p>介绍 urllib 时，可以将请求表示为数据结构，各个参数通过一个 Request 对象来表示。这里 requests 也可以做到，这个数据结构叫 Prepared Request</p>
<p>有了 Request 这个对象，就可以将请求当作独立的对象来看待，这样在队列调度时会非常方便</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests.sessions <span class="keyword">import</span> Session</span><br><span class="line">s = Session()</span><br><span class="line">r = requests.get(<span class="string">&#x27;http://xxx&#x27;</span>)</span><br><span class="line">prepped = s.prepare_request(r)</span><br><span class="line">r = s.send(prepped)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<p>调用 Session 的 prepare_request 方法将其转换为一个 Prepared Request 对象，然后调用 send 方法发送即可</p>
<h5 id="3-3-正则表达式"><a href="#3-3-正则表达式" class="headerlink" title="3.3 正则表达式"></a>3.3 正则表达式</h5><p>正则表达式测试工具 <a target="_blank" rel="noopener" href="http://tool.oschina.net/regex/">http://tool.oschina.net/regex/</a></p>
<h5 id="3-4-抓取猫眼电影排行"><a href="#3-4-抓取猫眼电影排行" class="headerlink" title="3.4 抓取猫眼电影排行"></a>3.4 抓取猫眼电影排行</h5><p>(爬不了了有滑块验证)</p>
<p>书本配套代码 <a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/MaoYan">https://github.com/Python3WebSpider/MaoYan</a></p>
<p>排行链接  <a target="_blank" rel="noopener" href="https://maoyan.com/board/4">https://maoyan.com/board/4</a></p>
<p>第二页链接  <a target="_blank" rel="noopener" href="https://maoyan.com/board/4?offset=10">https://maoyan.com/board/4?offset=10</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span>(<span class="params">url</span>):</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		headers = &#123;</span><br><span class="line">			<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_10; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50&#x27;</span></span><br><span class="line">		&#125;</span><br><span class="line">		response = requests.get(url, headers=headers)</span><br><span class="line">		<span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">			<span class="keyword">return</span> response.text</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">	<span class="keyword">except</span> RequestException:</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	url = <span class="string">&#x27;https://maoyan.com/board/4&#x27;</span></span><br><span class="line">	html = get_one_page(url)</span><br><span class="line">	print(html)</span><br></pre></td></tr></table></figure>

<p>可以通过浏览器查看源码，选择网络查看原始请求部分</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;board-index board-index-1&quot;</span>&gt;</span>1<span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/films/1200486&quot;</span> <span class="attr">title</span>=<span class="string">&quot;我不是药神&quot;</span> <span class="attr">class</span>=<span class="string">&quot;image-link&quot;</span> <span class="attr">data-act</span>=<span class="string">&quot;boarditem-click&quot;</span> <span class="attr">data-val</span>=<span class="string">&quot;&#123;movieId:1200486&#125;&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;//s3plus.meituan.net/v1/mss_e2821d7f0cfe4ac1bf9202ecf9590e67/cdn-prod/file:5788b470/image/loading_2.e3d934bf.png&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;poster-default&quot;</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-src</span>=<span class="string">&quot;https://p0.meituan.net/movie/414176cfa3fea8bed9b579e9f42766b9686649.jpg@160w_220h_1e_1c&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;我不是药神&quot;</span> <span class="attr">class</span>=<span class="string">&quot;board-img&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;board-item-main&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;board-item-content&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;movie-item-info&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;name&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/films/1200486&quot;</span> <span class="attr">title</span>=<span class="string">&quot;我不是药神&quot;</span> <span class="attr">data-act</span>=<span class="string">&quot;boarditem-click&quot;</span> <span class="attr">data-val</span>=<span class="string">&quot;&#123;movieId:1200486&#125;&quot;</span>&gt;</span>我不是药神<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;star&quot;</span>&gt;</span>主演：徐峥,周一围,王传君<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;releasetime&quot;</span>&gt;</span>上映时间：2018-07-05<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">		  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  		<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;movie-item-number score-num&quot;</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;score&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;integer&quot;</span>&gt;</span>9.<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fraction&quot;</span>&gt;</span>6<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span>        </span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>一部电影信息对应源码是一个 dd 节点</p>
<p>先获取排行信息，在 class 为 board-index 的 i 节点内，提取 i 节点内的信息</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;</span><br></pre></td></tr></table></figure>

<p>图片信息：dd 后面有个 a 节点，内部有两个 img 节点，第二个 img 节点的 data-src 属性是图片的链接，提取第二个 img 节点 data-sr 属性</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;</span><br></pre></td></tr></table></figure>

<p>电影名称：后面 p 节点内， class 为 name</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name.*?&gt;(.*?)&lt;/a&gt;</span><br></pre></td></tr></table></figure>

<p>findall 提取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name.*?&gt;(.*?)&lt;/a&gt;&#x27;</span>, re.S)</span><br><span class="line">items = re.findall(pattern, html)</span><br><span class="line">print(items)</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;https://p0.meituan.net/movie/414176cfa3fea8bed9b579e9f42766b9686649.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1200486&quot; title=&quot;我不是药神&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1200486&#125;&quot;&gt;我不是药神&#x27;</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;https://p0.meituan.net/movie/8112a8345d7f1d807d026282f2371008602126.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1297&quot; title=&quot;肖申克的救赎&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1297&#125;&quot;&gt;肖申克的救赎&#x27;</span>), (<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;https://p1.meituan.net/movie/c9b280de01549fcb71913edec05880585769972.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1206605&quot; title=&quot;绿皮书&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1206605&#125;&quot;&gt;绿皮书&#x27;</span>), (<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;https://p0.meituan.net/movie/609e45bd40346eb8b927381be8fb27a61760914.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1292&quot; title=&quot;海上钢琴师&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1292&#125;&quot;&gt;海上钢琴师&#x27;</span>), (<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;https://p1.meituan.net/movie/ac8f0004928fbce5a038a007b7c73cec746794.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1216365&quot; title=&quot;小偷家族&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1216365&#125;&quot;&gt;小偷家族&#x27;</span>), (<span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;https://p0.meituan.net/movie/61fea77024f83b3700603f6af93bf690585789.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1203&quot; title=&quot;霸王别姬&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1203&#125;&quot;&gt;霸王别姬&#x27;</span>), (<span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;https://p0.meituan.net/movie/005955214d5b3e50c910d7a511b0cb571445301.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1211270&quot; title=&quot;哪吒之魔童降世&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1211270&#125;&quot;&gt;哪吒之魔童降世&#x27;</span>), (<span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;https://p1.meituan.net/movie/580d81a2c78bf204f45323ddb4244b6c6821175.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/1303&quot; title=&quot;美丽人生&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:1303&#125;&quot;&gt;美丽人生&#x27;</span>), (<span class="string">&#x27;9&#x27;</span>, <span class="string">&#x27;https://p1.meituan.net/movie/6bea9af4524dfbd0b668eaa7e187c3df767253.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/4055&quot; title=&quot;这个杀手不太冷&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:4055&#125;&quot;&gt;这个杀手不太冷&#x27;</span>), (<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;https://p0.meituan.net/moviemachine/c2496a7290a72eac6081321898c347693550574.jpg@160w_220h_1e_1c&#x27;</span>, <span class="string">&#x27;&lt;a href=&quot;/films/416&quot; title=&quot;盗梦空间&quot; data-act=&quot;boarditem-click&quot; data-val=&quot;&#123;movieId:416&#125;&quot;&gt;盗梦空间&#x27;</span>)]</span><br></pre></td></tr></table></figure>

<p>写入文件</p>
<p>通过 JSON库的 dumps() 方法实现字典的序列化，ensure_ascii 为 False，保证输出结果是中文形式而不是 Unicode 编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file</span>(<span class="params">content</span>):</span></span><br><span class="line">	<span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;result.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f: <span class="comment">#a appending追加写入</span></span><br><span class="line">		print(<span class="built_in">type</span>(json.dumps(content)))</span><br><span class="line">		f.write(json.dumps(content, ensure_ascii=<span class="literal">False</span>)+<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>分页爬取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">offset</span>):</span></span><br><span class="line">	url = <span class="string">&#x27;https://maoyan.com/board/4?offset=&#x27;</span> + <span class="built_in">str</span>(offset) </span><br><span class="line">	html = get_one_page(url)</span><br><span class="line">	pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name.*?&gt;(.*?)&lt;/a&gt;&#x27;</span>, re.S)</span><br><span class="line">	items = re.findall(pattern, html)</span><br><span class="line">	print(items)</span><br><span class="line">	write_to_file(items)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">		main(offset=i*<span class="number">10</span>)</span><br><span class="line">		time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h4 id=""><a href="#" class="headerlink" title=""></a></h4>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/04/11/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" rel="prev" title="Python3网络爬虫开发实战-正则表达式">
                  <i class="fa fa-chevron-left"></i> Python3网络爬虫开发实战-正则表达式
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/04/11/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98-%E8%A7%A3%E6%9E%90%E5%BA%93%E4%BD%BF%E7%94%A8/" rel="next" title="Python3网络爬虫开发实战-解析库使用">
                  Python3网络爬虫开发实战-解析库使用 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">daxun</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/local-search.js"></script>















  








  

  

</body>
</html>
