<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"8.0.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="音视频基础数字音频将模拟信号转换为数字信号的过程  采样  在时间轴上对信号进行数字化。 根据奈奎斯特定理（也称为采样定理），按比声音最高频率高2倍以上的频率对声音进行采样（也称为AD转换） 比如：对高质量音频信号，其频率范围是20Hz~20kHz（人耳能够听到的频率范围），所以采样频率一般为44.1kHz，这样就可以保证采样声音达到20kHz也能被数字化，从而使得经过数字化处理之后，人耳听到的声">
<meta property="og:type" content="article">
<meta property="og:title" content="音视频开发">
<meta property="og:url" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="音视频基础数字音频将模拟信号转换为数字信号的过程  采样  在时间轴上对信号进行数字化。 根据奈奎斯特定理（也称为采样定理），按比声音最高频率高2倍以上的频率对声音进行采样（也称为AD转换） 比如：对高质量音频信号，其频率范围是20Hz~20kHz（人耳能够听到的频率范围），所以采样频率一般为44.1kHz，这样就可以保证采样声音达到20kHz也能被数字化，从而使得经过数字化处理之后，人耳听到的声">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/AudioUnit.png">
<meta property="og:image" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/remoteio.png">
<meta property="og:image" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/音视频开发/IOWithoutRenderCallback.png">
<meta property="og:image" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/02.png">
<meta property="og:image" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/01.png">
<meta property="article:published_time" content="2021-08-03T04:26:37.000Z">
<meta property="article:modified_time" content="2021-08-16T11:56:36.234Z">
<meta property="article:author" content="daxun">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/AudioUnit.png">


<link rel="canonical" href="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>音视频开发 | Hexo</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">简单记录下</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9F%B3%E8%A7%86%E9%A2%91%E5%9F%BA%E7%A1%80"><span class="nav-number">1.</span> <span class="nav-text">音视频基础</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E9%9F%B3%E9%A2%91"><span class="nav-number">1.1.</span> <span class="nav-text">数字音频</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9F%B3%E9%A2%91%E7%BC%96%E7%A0%81"><span class="nav-number">1.2.</span> <span class="nav-text">音频编码</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81"><span class="nav-number">1.3.</span> <span class="nav-text">视频编码</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BC%96%E7%A0%81%E6%A6%82%E5%BF%B5"><span class="nav-number">1.4.</span> <span class="nav-text">编码概念</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-number">2.</span> <span class="nav-text">环境搭建</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AudioUnit"><span class="nav-number">3.</span> <span class="nav-text">AudioUnit</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#AudioSession"><span class="nav-number">3.0.1.</span> <span class="nav-text">AudioSession</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA-AudioUnit"><span class="nav-number">3.0.2.</span> <span class="nav-text">构建 AudioUnit</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#AudioUnit-%E9%80%9A%E7%94%A8%E5%8F%82%E6%95%B0"><span class="nav-number">3.0.3.</span> <span class="nav-text">AudioUnit 通用参数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#AudioUnit-%E5%88%86%E7%B1%BB"><span class="nav-number">3.0.4.</span> <span class="nav-text">AudioUnit 分类</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%9E%84%E9%80%A0%E4%B8%80%E4%B8%AA-AUGraph"><span class="nav-number">3.0.5.</span> <span class="nav-text">构造一个 AUGraph</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9F%B3%E9%A2%91%E9%87%87%E9%9B%86"><span class="nav-number">4.</span> <span class="nav-text">音频采集</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">daxun</p>
  <div class="site-description" itemprop="description">简单记录下</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">43</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="daxun">
      <meta itemprop="description" content="简单记录下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          音视频开发
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-03 12:26:37" itemprop="dateCreated datePublished" datetime="2021-08-03T12:26:37+08:00">2021-08-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-08-16 19:56:36" itemprop="dateModified" datetime="2021-08-16T19:56:36+08:00">2021-08-16</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h4 id="音视频基础"><a href="#音视频基础" class="headerlink" title="音视频基础"></a>音视频基础</h4><h5 id="数字音频"><a href="#数字音频" class="headerlink" title="数字音频"></a>数字音频</h5><p>将模拟信号转换为数字信号的过程</p>
<ul>
<li>采样</li>
</ul>
<p>在时间轴上对信号进行数字化。</p>
<p>根据奈奎斯特定理（也称为采样定理），按比声音最高频率高2倍以上的频率对声音进行采样（也称为AD转换）</p>
<p>比如：对高质量音频信号，其频率范围是20Hz~20kHz（人耳能够听到的频率范围），所以采样频率一般为44.1kHz，这样就可以保证采样声音达到20kHz也能被数字化，从而使得经过数字化处理之后，人耳听到的声音质量不会被降低</p>
<p>44.1kHz就是代表1秒会采样44100次</p>
<ul>
<li>量化</li>
</ul>
<p>在幅度轴上对信号进行数字化</p>
<ul>
<li>编码</li>
</ul>
<p>按照一定的格式记录采样和量化后的数字数据</p>
<p>音频格式有很多种，音频裸数据格式就是脉冲编码调制（PCM）数据。</p>
<p>描述一段PCM数据一般需要以下几个概念：<br>量化格式（sampleFormat）<br>采样率（sampleRate）<br>声道数（channel）</p>
<p>以CD音质为例：量化格式为16比特（2字节），采样率为44100，声道数为2，这些信息就描述</p>
<p>CD音质的比特率：即1秒时间内的比特数目，衡量音频数据单位时间内的容量大小<br>44100 * 16 * 2 = 1378.125kbps</p>
<p>那么1分钟内，这类CD音质的数据需要占据多大内存空间？<br>1378.125 * 60 / 8 / 1024 = 10.09M</p>
<p>如果sampleFormat更加精确（比如用4字节来描述一个采样）或者sampleRate更加密集（比如48kHz的采样率）那么所占的存储空间会更大，同时能够描述的声音细节会越精确</p>
<h5 id="音频编码"><a href="#音频编码" class="headerlink" title="音频编码"></a>音频编码</h5><p>通过计算CD音质的数据采样，每分钟需要存储10.1M，若要在网络中实时在线传播的话，数据量可能就太大了，需要进行压缩编码</p>
<p>压缩算法包括有损压缩和无损压缩，无损压缩是指解压后的数据可以完全恢复，有损压缩解压后的数据不能完全恢复，会丢失一部分信息，压缩比越小，丢失的信息就越多</p>
<p>压缩编码实际上是压缩掉冗余信号，冗余信号是指不能被人耳感知到的信号</p>
<p>常见压缩编码格式：</p>
<ol>
<li>WAV编码</li>
</ol>
<p>在PCM数据格式前加上44字节，分辨用来描述PCM的采样率、声道数、数据格式等信息</p>
<p>特点：音质非常好，大量软件都支持其播放</p>
<p>适合场所：多媒体开发中的中间文件，保存音乐和音效素材</p>
<ol start="2">
<li>MP3编码</li>
</ol>
<p>具有不错的压缩比，听感上非常解决WAV文件</p>
<p>特点：音质在128kbps/s以上表现还不错，压缩比比较高，大量软件和硬件都支持，兼容性好</p>
<p>适合场所：搞比特率下对兼容性有要求的音乐欣赏</p>
<ol start="3">
<li>AAC编码</li>
</ol>
<p>目前比较热门的有损压缩编码技术，并衍生出了LC-AAC、HE-AAC、HE-AAC v2三种主要编码格式。</p>
<p>LC-AAC 是比较传统的AAC，主要应用于中高码率场景编码（&gt;=80Kbit/s）</p>
<p>HE-AAC 主要应用于低码率场景的编码（&lt;=80Kbit/s）</p>
<p>HE-AAC v2 主要应用于低码率场景的编码（&lt;=48Kbit/s）</p>
<p>特点：在小于128Kbit/s的码率下表现优异，多用于视频中的音频编码</p>
<ol start="4">
<li>Ogg编码</li>
</ol>
<p>一种非常有潜力的编码，各种码率下都有比较优秀的表现，尤其在中低码率场景下。可以用更下的码率达到更好的音质，128Kbit/s的Ogg币192Kbit/s甚至更高码率的MP3还要出色，但目前还没有媒体服务软件的支持</p>
<p>特点：可以用比MP3更小的码率实现比MP3更好的音质，高中低码率下均有良好表现，兼容性不够好，流媒体特性不支持</p>
<p>适用场景：语音聊天的音频消息场景</p>
<h5 id="视频编码"><a href="#视频编码" class="headerlink" title="视频编码"></a>视频编码</h5><p>视频压缩也是通过去除冗余信息来进行压缩的</p>
<p>使用帧间编码技术可以去除时间上冗余信息</p>
<p>使用帧内编码技术可以去除空间上冗余信息</p>
<h5 id="编码概念"><a href="#编码概念" class="headerlink" title="编码概念"></a>编码概念</h5><p>MPEG 算法适用于动态视频的压缩算法，它除了对单幅图像进行编码外，还利用图像序列中的相关原则去除冗余，大大提高视频压缩比。</p>
<p>MPEG主要包括几个版本：Mpeg1（用于VCD）、Mpeg2（用于DVD）、Mpeg4 AVC（现在流媒体使用最多的就是它了）</p>
<p>相比较与ISO指定的MPEG的视频压缩标准，ITU-T制定的H.261、H.262、H.263、H.264一系列视频编码标准是一套单独的体系。其中H.264集中了以往标准的所有有点，采用简洁设计，使得它比Mpeg4更容易推广，现在使用最多的就是H.264标准</p>
<ul>
<li>I帧</li>
</ul>
<p>帧内编码帧，</p>
<ul>
<li><p>P帧</p>
</li>
<li><p>B帧</p>
</li>
</ul>
<h4 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h4><p>项目增加C++支持，OC语法支持混编，把引用C++的OC类后缀名改为.mm，就可以和C++一块编译了</p>
<p>LAME 一种MP3编码引擎，转码成MP3格式的音频文件时，最常用的就是LAME库</p>
<p>编译LAME，<a target="_blank" rel="noopener" href="https://lame.sourceforge.io/download.php">LAME</a> 下载不下来，使用别人编译好的版本 <a target="_blank" rel="noopener" href="https://github.com/JIANHUI2015/RemoteIODemo">lame </a> 两个文件 lame.h 和 libmp3lame.a，拖进项目就可以了</p>
<h4 id="AudioUnit"><a href="#AudioUnit" class="headerlink" title="AudioUnit"></a>AudioUnit</h4><p>iOS 平台上所有的音频框架底层都是基于 AudioUnit 实现的</p>
<p>较高层次的音频框架包括：Mediia Player、AVFoundation、OpenAL、AudioToolbox，这些框架都封装了 AudioUnit，提供了更高层次的API（功能更少，职责更单一接口）</p>
<p><img src="/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/AudioUnit.png" alt="AudioUnit"></p>
<p>如果对音频需要更高成都的控制、性能以及灵活性，或者想要使用一些特殊功能（回声消除）时，可以直接使用 AudioUnit API，以下场景更适合使用 AudioUnit</p>
<ul>
<li>想使用低延迟的音频 I/O（input或者output）比如说 VoIP 的应用场景下</li>
<li>多路声音的合成并且回放，比如游戏或者音乐合成器的应用</li>
<li>使用 AudioUnit 里提供的特殊功能，比如：回声消除、Mix两轨音频、以及均衡器、压缩器、混响器等效果器</li>
<li>需要图状结构来处理音频，可以将音频处理模块组装到灵活的图状结构中</li>
</ul>
<h6 id="AudioSession"><a href="#AudioSession" class="headerlink" title="AudioSession"></a>AudioSession</h6><p>音频会话，用于管理与获取 iOS 设备音频的硬件信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">AVAudioSession *audioSession &#x3D; [AVAudioSession sharedInstance];</span><br><span class="line">NSError *error &#x3D; nil;</span><br><span class="line">&#x2F;&#x2F;设置以何种方式使用音频硬件</span><br><span class="line">[audioSession setCategory:AVAudioSessionCategoryPlayAndRecord error:&amp;error];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置I&#x2F;O的Buffer，Buffer越小则说明延迟越低</span><br><span class="line">NSTimeInterval bufferDuration &#x3D; 0.002;</span><br><span class="line">[audioSession setPreferredIOBufferDuration:bufferDuration error:&amp;error];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置采样频率 让硬件设备按照设置的采样频率来采集或者播放音频</span><br><span class="line">double hwSampleRate &#x3D; 44100.0;</span><br><span class="line">[audioSession setPreferredSampleRate:hwSampleRate error:&amp;error];</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置完所有参数之后就可以激活 AudioSession</span><br><span class="line">[audioSession setActive:YES error:&amp;error];</span><br></pre></td></tr></table></figure>

<h6 id="构建-AudioUnit"><a href="#构建-AudioUnit" class="headerlink" title="构建 AudioUnit"></a>构建 AudioUnit</h6><p>创建并启用 AudioSession 音频会话之后就可以构建 AudioUnit 了</p>
<p>需要指定类型（Type）、子类型（subtype）以及厂商（Manufacture），利用三个变量可以完整描述一个 AudioUnit 了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">AudioComponentDescription ioUnitDescription;</span><br><span class="line">ioUnitDescription.componentType &#x3D; kAudioUnitType_Output;</span><br><span class="line">ioUnitDescription.componentSubType &#x3D; kAudioUnitSubType_RemoteIO;</span><br><span class="line">&#x2F;&#x2F;比较固定 直接kAudioUnitManufacturer_Apple就可以了</span><br><span class="line">ioUnitDescription.componentManufacturer &#x3D; kAudioUnitManufacturer_Apple;</span><br><span class="line">ioUnitDescription.componentFlags &#x3D; 0;</span><br><span class="line">ioUnitDescription.componentFlagsMask &#x3D; 0;</span><br></pre></td></tr></table></figure>

<p>上面代码构造了 RemoteIO 类型的 AudioUnit 描述的结构体，下面构造 AudioUnit</p>
<p>两种方式构建：1. 使用 AudioUnit 裸的创建方式 2. 使用 AUGraph 和 AUNode 的 Wrapper 来构建</p>
<ol>
<li>裸的创建方式</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;根据 AudioUnit 的描述，找出实际的 AudioUnit 类型</span><br><span class="line">AudioComponent ioUnitRef &#x3D; AudioComponentFindNext(NULL, &amp;ioUnitDescription);</span><br><span class="line">&#x2F;&#x2F;声明一个 AudioUnit 引用</span><br><span class="line">AudioUnit ioUnitInstance;</span><br><span class="line">&#x2F;&#x2F;根据类型创建 AudioUnit 实例</span><br><span class="line">AudioComponentInstanceNew(ioUnitRef, &amp;ioUnitInstance);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>AUGraph 创建方式（扩展性更高）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;声明并实例化一个AUGraph</span><br><span class="line">AUGraph processingGraph;</span><br><span class="line">NewAUGraph(&amp;processingGraph);</span><br><span class="line">&#x2F;&#x2F;按照AudioUnit的描述在AUGraph中增加一个AUNode</span><br><span class="line">AUNode ioNode;</span><br><span class="line">AUGraphAddNode(processingGraph, &amp;ioUnitDescription, &amp;ioNode);</span><br><span class="line">&#x2F;&#x2F;打开AUGraph，必须在获取AudioUnit之前打开整个AUGraph</span><br><span class="line">AUGraphOpen(processingGraph);</span><br><span class="line">&#x2F;&#x2F;在AUGraph中的某个Node里获得AudioUnit的引用</span><br><span class="line">AudioUnit ioUnit;</span><br><span class="line">AUGraphNodeInfo(processingGraph, ioNode, NULL, &amp;ioUnit);</span><br></pre></td></tr></table></figure>

<h6 id="AudioUnit-通用参数"><a href="#AudioUnit-通用参数" class="headerlink" title="AudioUnit 通用参数"></a>AudioUnit 通用参数</h6><p>以 RemoteIO  为例，RemoteIO 这个 AudioUnit 是与硬件 IO 相关的一个 Unit，分为输入和输出端，输入端一般是麦克风，输出端一般指扬声器或者耳机，如果需要同事使用输入输出，即K歌应用中的耳返功能，则需要做一些设置将他们连接起来</p>
<img src="remoteio.png" alt="remoteio" style="zoom:90%;" />

<p>RemoteIO Unit 分为 Element0 和 Element 1，Element0 控制输出端，Element1 控制输入端，每个 Element 又分为 Input Scope 和 Output Scope。</p>
<p>如果想要使用扬声器的声音播放功能，必须将这个 Unit 的 Element0 的 OutputScope 和 Speaker 进行连接</p>
<p>如果想要使用麦克风录音功能，必须将这个Unit 的 Element1 的 InputScope 和麦克风进行连接</p>
<p>使用扬声器代码：把 RemoteIOUnit的 Element0 的 OutputScope 连接到 Speaker 上，会返回一个 OSStatus 值，使用自定义 CheckStatus 函数判断错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">OSStatus status &#x3D; noErr;</span><br><span class="line">UInt32 oneFlag &#x3D; 1;</span><br><span class="line">&#x2F;&#x2F;Element 0</span><br><span class="line">UInt32 busZero &#x3D; 0;</span><br><span class="line">status &#x3D; AudioUnitSetProperty(ioUnit,</span><br><span class="line">                              kAudioOutputUnitProperty_EnableIO,</span><br><span class="line">                              kAudioUnitScope_Output,</span><br><span class="line">                              busZero,</span><br><span class="line">                              &amp;oneFlag,</span><br><span class="line">                              sizeof(oneFlag));</span><br><span class="line">&#x2F;&#x2F;自定义的CheckStatus函数来判断错误并输出</span><br><span class="line">CheckStatus(status, @&quot;Could not Connect To Speaker&quot;, YES);</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">CheckStatus</span><span class="params">(OSStatus status, NSString *message, BOOL fatal)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (status != noErr) &#123;</span><br><span class="line">        <span class="keyword">char</span> fourCC[<span class="number">16</span>];</span><br><span class="line">        *(UInt32 *)fourCC = CFSwapInt32HostToBig(status);</span><br><span class="line">        fourCC[<span class="number">4</span>] = <span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isprint</span>(fourCC[<span class="number">0</span>]) &amp;&amp;</span><br><span class="line">            <span class="built_in">isprint</span>(fourCC[<span class="number">1</span>]) &amp;&amp;</span><br><span class="line">            <span class="built_in">isprint</span>(fourCC[<span class="number">2</span>]) &amp;&amp;</span><br><span class="line">            <span class="built_in">isprint</span>(fourCC[<span class="number">3</span>])) &#123;</span><br><span class="line">            NSLog(@<span class="string">&quot;%@: %s&quot;</span>, message, fourCC);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            NSLog(@<span class="string">&quot;%@: %d&quot;</span>, message, (<span class="keyword">int</span>)status);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (fatal) &#123;</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启用麦克风：把 RemoteIOUnit 的 Element1 的 InputScope 连接上麦克风</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;Element 1</span><br><span class="line">UInt32 busOne &#x3D; 1;</span><br><span class="line">AudioUnitSetProperty(ioUnit,</span><br><span class="line">                     kAudioOutputUnitProperty_EnableIO,</span><br><span class="line">                     kAudioUnitScope_Input,</span><br><span class="line">                     busOne,</span><br><span class="line">                     &amp;oneFlag,</span><br><span class="line">                     sizeof(oneFlag));</span><br></pre></td></tr></table></figure>

<p>连接成功后，就该给 AudioUnit 设置数据格式了，AudioUnit 数据格式分为输入和输出两个部分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;设置AudioUnit数据格式 AudioStreamBasicDescription描述音视频具体格式</span><br><span class="line">UInt32 bytesPerSample &#x3D; sizeof(Float32);</span><br><span class="line">AudioStreamBasicDescription asbd;</span><br><span class="line">bzero(&amp;asbd, sizeof(asbd));</span><br><span class="line"></span><br><span class="line">double _samplerRate &#x3D; 44100.0;</span><br><span class="line">UInt32 channels &#x3D; 2;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;指定音频的编码格式 此处 PCM</span><br><span class="line">asbd.mFormatID &#x3D; kAudioFormatLinearPCM;</span><br><span class="line">&#x2F;&#x2F;采样率</span><br><span class="line">asbd.mSampleRate &#x3D; _samplerRate;</span><br><span class="line">&#x2F;&#x2F;声道数 1单身到 2立体声</span><br><span class="line">asbd.mChannelsPerFrame &#x3D; channels;</span><br><span class="line">&#x2F;&#x2F;每个Packers有几个Frame</span><br><span class="line">asbd.mFramesPerPacket &#x3D; 1;</span><br><span class="line">&#x2F;&#x2F;mFormatFlags 描述声音表示格式的参数</span><br><span class="line">&#x2F;&#x2F;kAudioFormatFlagsNativeFloatPacked 指定每个sample的表示格式是Float格式；</span><br><span class="line">&#x2F;&#x2F;kAudioFormatFlagIsNonInterleaved   左右声道是非交错存放的</span><br><span class="line">&#x2F;&#x2F;实际的音频数据会存储在一个 AudioBufferList结构中的变量mBuffers中，如果mFormatFlags指定的是 NonInterleaved，那么左声道就会在mBuffers[0]里面，右声道就会在 mBuffers[1]里面</span><br><span class="line">asbd.mFormatFlags &#x3D; kAudioFormatFlagsNativeFloatPacked | kAudioFormatFlagIsNonInterleaved;</span><br><span class="line">&#x2F;&#x2F;一个声道的音频数据用多少位来表示</span><br><span class="line">asbd.mBitsPerChannel &#x3D; 8 * bytesPerSample;</span><br><span class="line">&#x2F;&#x2F;每一帧有多少字节 mBytesPerFrame和mBytesPerPacket根据mFormatFlags来分配</span><br><span class="line">&#x2F;&#x2F;NonInterleaved情况下bytesPerSample(因为左右声道分开存放的)；Interleaved的话bytesPerSample * channels(因为左右声道是交错存放)</span><br><span class="line">asbd.mBytesPerFrame &#x3D; bytesPerSample;</span><br><span class="line">&#x2F;&#x2F;每个包有多少字节</span><br><span class="line">asbd.mBytesPerPacket &#x3D; bytesPerSample;</span><br></pre></td></tr></table></figure>

<p>构造好了 BasicDescription 结构体，将结构体设置给对应 AudioUnit</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;构造好了BasicDescription结构体，将这结构体设置给对应的AudioUnit</span><br><span class="line">AudioUnitSetProperty(ioUnit,</span><br><span class="line">                     kAudioUnitProperty_StreamFormat,</span><br><span class="line">                     kAudioUnitScope_Output, 1,</span><br><span class="line">                     &amp;asbd, sizeof(asbd));</span><br></pre></td></tr></table></figure>



<ul>
<li>kAudioOutputUnitProperty_EnableIO 用于启用或禁用 I/O Unit上的输入输出，默认启用输出但禁用输入</li>
<li>kAudioUnitProperty_ElementCount 配置 Mixer Unit上的输入元素数量</li>
<li>kAudioUnitProperty_MaximumFramesPerSlice 指定音频数据最大帧数</li>
<li>kAudioUnitProperty_StreamFormat 指定特定音频单元输入或输出总线的音频流数据格式</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">UInt32 maximumFramesPerSlice &#x3D; 4096;</span><br><span class="line">AudioUnitSetProperty (</span><br><span class="line">              _ioUnit,</span><br><span class="line">              kAudioUnitProperty_MaximumFramesPerSlice,</span><br><span class="line">              kAudioUnitScope_Global,0,</span><br><span class="line">              &amp;maximumFramesPerSlice,</span><br><span class="line">              sizeof (maximumFramesPerSlice));</span><br></pre></td></tr></table></figure>

<p>Global Scope适用于整个AudioUnit，不与任何特定音频流相关，只有1个元素即0，某些属性，如每个切片最大帧数，仅适用于 Global Scope</p>
<p>设置音频数据流格式</p>
<img src="音视频开发/IOWithoutRenderCallback.png" alt="IOWithoutRenderCallback" style="zoom:70%;" />













<h6 id="AudioUnit-分类"><a href="#AudioUnit-分类" class="headerlink" title="AudioUnit 分类"></a>AudioUnit 分类</h6><ol>
<li>Effect Unit</li>
</ol>
<p>类型是 <code>kAudioUnitType_Effect</code>，主要提供声音特效处理的功能，子类型如下：</p>
<p>均衡器效果：子类型是 <code>kAudioUnitSubType_NBandEQ</code>，主要作用 是为声音的某些频带增强或者减弱能量，该效果器需要指定多个频带， 然后为各个频带设置宽度以及增益，最终将改变声音在频域上的能量分布</p>
<p>压缩效果器：子类型是 <code>kAudioUnitSubType_DynamicsProcessor</code>，主 要作用是当声音较小的时候可以提高声音的能量，当声音的能量超过了 设置的阈值时，可以降低声音的能量，当然应合理地设置作用时间、释 放时间以及触发值，使得最终可以将声音在时域上的能量压缩到一定范 围之内</p>
<p>混响效果器：子类型是 <code>kAudioUnitSubType_Reverb2</code>，对于人声处 理来讲这是非常重要的效果器，可以想象自己身处在一个空房子中，如 果有非常多的反射声和原始声音叠加在一起，那么从听感上可能会更有 震撼力，但是同时原始声音也会变得更加模糊，原始声音的一些细节会 被遮盖掉，所以混响设置的大或者小对于不同的人来讲会很不一致，可以根据自己的喜好来进行设置</p>
<p>Effect Unit下最常使用的就是上述三种效果器，其下还有很多种子类型的效果器，像高通(High Pass)、低通(Low Pass)、带通 (Band Pass)、延迟(Delay)、压限(Limiter)等效果器</p>
<ol start="2">
<li>Mixer Units</li>
</ol>
<p>类型是 <code>kAudioUnitType_Mixer</code>，主要提供 Mix 多路声音的功能，子类型如下：</p>
<p>3D Mixer：该效果器在移动身上无法使用</p>
<p>MultiChannelMixer：子类型是 <code>kAudioUnitSubType_MultiChannelMixer</code>，它是多路声音混音的效果器，可以接收多路音频的输入，还可以 分别调整每一路音频的增益与开关，并将多路音频合并成一路，该效果 器在处理音频的图状结构中非常有用</p>
<p>OutputScope仅设置采样率</p>
<p>默认情况下 kAudioUnitProperty_MaximumFramesPerSlice 设置为1024，如果在屏幕锁定情况下播放音频，必须增加此属性值，除非音频输入处于活动状态</p>
<p>如果音频活动处于活动状态，无需为 kAudioUnitProperty_MaximumFramesPerSlice 设置值</p>
<p>如果音频输入不活跃，将此属性设置为 4096</p>
<ol start="3">
<li>I/O Units</li>
</ol>
<p>类型是 <code>kAudioUnitType_Output</code>，主要提供的就是I/O的功能</p>
<p>RemoteIO：子类型是 <code>kAudioUnitSubType_RemoteIO</code>，是用来采集音频与播放音频的</p>
<p>Generic Output：子类型是 <code>kAudioUnitSubType_GenericOutput</code>，当 开发者需要进行离线处理，或者说在AUGraph中不使用Speaker(扬声 器)来驱动整个数据流，而是希望使用一个输出(可以放入内存队列或 者进行磁盘I/O操作)来驱动数据流时，就使用该子类型</p>
<ol start="4">
<li>Format Converter Units</li>
</ol>
<p>类型是 <code>kAudioUnitType_FormatConverter</code>，主要用于提供格式转换 的功能，比如:采样格式由Float到SInt16的转换、交错和平铺的格式转换、单双声道的转换等</p>
<p>AUConverter：子类型是 <code>kAudioUnitSubType_AUConverter</code>，当某些效果器对输入的音频格式有 明确的要求时(比如3D Mixer Unit就必须使用UInt16格式的sample)， 或者开发者将音频数据输入给一些其他的编码器进行编码，又或者开发 者想使用SInt16格式的PCM裸数据在其他CPU上进行音频算法计算等的 场景下，就需要使用到这个ConverterNode了。下面来看一个比较典型的 场景，我们自定义一个音频播放器(代码仓库中的AudioPlayer项目)， 由FFmpeg解码出来的PCM数据是SInt16格式的，因此不能直接输送给 RemoteIO Unit进行播放，所以需要构建一个ConvertNode将SInt16格式 表示的数据转换为Float32格式表示的数据，然后再输送给RemoteIO Unit，最终才能正常播放出来</p>
<p>Time Pitch:子类型是 <code>kAudioUnitSubType_NewTimePitch</code>，即变速 变调效果器，这是一个很有意思的效果器，可以对声音的音高、速度进 行调整，像“会说话的Tom猫”类似的应用场景就可以使用这个效果器来 实现</p>
<ol start="5">
<li>Generator Units</li>
</ol>
<p>类型是 <code>kAudioUnitType_Generator</code>，在开发中我们经常使用它来提供播放器的功能</p>
<p>AudioFilePlayer：子类型是 <code>kAudioUnitSubType_AudioFilePlayer</code>， 在 AudioUnit 里面，如果我们的输入不是麦克风，而希望其是一个媒体 文件，当然，也可以类似于代码仓库中的 AudioPlayer 项目自行解码，转 换之后将数据输送给 RemoteIO Unit 播放出来，但是其实还有一种更加简 单、方便的方式，那就是使用 AudioFilePlayer 这个 AudioUnit，可以参考 代码仓库中的 AUPlayer 项目，该项目就是利用 AudioFilePlayer 作为输入 数据源来提供数据的。需要注意的是，必须在初始化 AUGraph 之后，再 去配置 AudioFilePlayer 的数据源以及播放范围等属性，否则就会出现错 误，其实数据源还是会调用 AudioFile 的解码功能，将媒体文件中的压缩 数据解压成为PCM裸数据，最终再交给 AudioFilePlayer Unit 进行后续处 理</p>
<h6 id="构造一个-AUGraph"><a href="#构造一个-AUGraph" class="headerlink" title="构造一个 AUGraph"></a>构造一个 AUGraph</h6><p>实际的K歌应用场景，会对用户发出的声音进行处理，并且立即给 用户一个耳返(在50ms之内将声音输出到耳机中，让用户可以听到)。 那么如何让 RemoteIOUnit 利用麦克风采集出来的声音，经过中间效果器 的处理，最终输出到 Speaker 中播放给用户呢？如何 以AUGraph的方式将声音采集、声音处理以及声音输出的整个过程管理 起来</p>
<p>首先要知道数据可以在通道中传递是由最右端 Speaker(RemoteIO Unit)来驱动的，它会向其前一级——AUNode要数 据，然后它的前一级会继续向上一级节点要数据，并最终从 RemoteIOUnit的Element1 (即麦克风)中要数据，这样就可以将数据按 照相反的方向一级一级地传递下去，最终传递到RemoteIOUnit的 Element0(即Speaker)并播放给用户听到。当然你可能会想到离线处理 的时候应该由谁来进行驱动呢?其实在进行离线处理的时候应该使用 Mixer Unit大类型下面子类型为Generic Output的AudioUnit来做驱动端。 那么这些AudioUnit或者说AUNode是如何进行连接的呢?有两种方式， 第一种方式是直接将AUNode连接起来;第二种方式是通过回调的方式 将两个AUNode连接起来</p>
<p><img src="/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/02.png" alt="02"></p>
<ul>
<li>直接连接</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AUGraphConnectNodeInput(mPlayerGraph, mPlayerNode, 0, mPlayerIONode, 0);</span><br></pre></td></tr></table></figure>

<p>AUPlayer实例中的一段代码，目标是将Audio File Player Unit和RemoteIO Unit直接连接起来，当RemoteIO Unit需要播放数据的时 候，就会调用AudioFilePlayer Unit来获取数据，这样就把这两个 AudioUnit连接起来了</p>
<ul>
<li>回调方式</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">AURenderCallbackStruct renderProc;</span><br><span class="line">renderProc.inputProc &#x3D; &amp;inputAvailableCallback;</span><br><span class="line">renderProc.inputProcRefCon &#x3D; (__bridge void *)self;</span><br><span class="line">AUGraphSetNodeInputCallback(mGraph, ioNode, 0, &amp;finalRenderProc);</span><br></pre></td></tr></table></figure>

<p>这段代码首先是构造一个AURenderCallback的结构体，并指定一个 回调函数，然后设置给RemoteIO Unit的输入端，当RemoteIO Unit需要 数据输入的时候就会回调该回调函数，回调函数代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">static OSStatus renderCallback(void *inRefCon, AudioUnitRenderActionFlags</span><br><span class="line">           *ioActionFlags, const AudioTimeStamp *inTimeStamp, UInt32</span><br><span class="line">           inBusNumber, UInt32 inNumberFrames, AudioBufferList *ioData)</span><br><span class="line"> &#123;</span><br><span class="line">     OSStatus result &#x3D; noErr;</span><br><span class="line">     __unsafe_unretained AUGraphRecorder *THIS &#x3D; (__bridge</span><br><span class="line">             AUGraphRecorder *)inRefCon;</span><br><span class="line">     AudioUnitRender(THIS-&gt;mixerUnit, ioActionFlags, inTimeStamp, 0,</span><br><span class="line">             inNumberFrames, ioData);</span><br><span class="line">     result &#x3D; ExtAudioFileWriteAsync(THIS-&gt;finalAudioFile, inNumberFrames,</span><br><span class="line">             ioData);</span><br><span class="line">     return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>该回调函数主要完成两件事情:第一件事情是去Mixer Unit里面要 数据，通过调用AudioUnitRender的方式来驱动Mixer Unit获取数据，得 到数据之后放入ioData中，从而填充回调方法中的参数，将Mixer Unit与 RemoteIO Unit连接了起来;第二件事情则是利用ExtAudioFile将这段声 音编码并写入本地磁盘的一个文件中</p>
<p>本节的代码仓库中包含了两个实例项目:一个是AUPlayer，利用 AudioFilePlayer Unit和RemoteIO Unit做了一个最简单的播放器;另外一个是AudioPlayer，它会利用FFmpeg进行解码操作，解码出来的是SInt16 格式表示的数据，然后再通过一个ConvertNode将其转换为Float32格式 表示的数据，最终输送给RemoteIO Unit进行播放。将这两个项目对比来 看，第二种方式十分不便</p>
<h4 id="音频采集"><a href="#音频采集" class="headerlink" title="音频采集"></a>音频采集</h4><p>示例代码 AudioRecorder</p>
<p>如果想要直接指定一个路径，可以将录制的音频编码到文件中，可以使用 <code> AVAudioRecorder</code>，优点是简单易用</p>
<p>但如果想要实时在内存中获取录音数据来说，限制性非常强，iOS提供了两个层次API来协助实现</p>
<p><code>AudioQueue</code>：是AudioUnit更高级的封装，功能更单一，接口调用更简单，如果仅仅要获取内存中的录音数据，然后再进行编码输出，用更高级的AudioQueue的API会更好些</p>
<p><code>AudioUnit</code>：如果要使用更多音效处理，以及实时的监听（耳机中听到自己说话），使用AudioUnit会更方便一些</p>
<p>要使用 AudioUnit，需要通过 AudioSession 来开启硬件设备以及对硬件设备做一些设置，然后才能使用 AudioUnit</p>
<ol>
<li>获取 AVAudioSession 实例</li>
<li>为 AVAudioSession 设置类别，录音的同时为用户输送监听耳返，类别使用 AVAudioSessionCategoryPlayAndRecord，</li>
<li>为 AVAudioSession 设置预设采样率</li>
<li>启用 AVAudioSession</li>
<li>为 AVAudioSession 设置路由监听，采集音频或视频输出的路线发生变化时（比如拔出耳机、蓝牙设备连接成功）回调此方法，以便可以重新设置使用当前最新的麦克风或扬声器</li>
</ol>
<p>接下来构造应用所使用的 AUGraph，因为这里要使用录音功能，所以需要启用RemoteIO这个AudioUnit 的InputElement。RemoteIO 这个 AudioUnit 比较特别，Input-Element实际 上使用的是麦克风，而OutputElement使用的则是扬声器，所以这里首先 会启用 RemoteIOUnit 的 InputElement。</p>
<p>为了支持所开发的App可以在后续 Mix 一轨伴奏这一扩展功能，在AUGraph中需要增加 MultiChannelMixer 这个 AudioUnit。由于每个 AudioUnit 的输入输出格式并不相同，所以这 里还要使用AudioConvert这个AudioUnit将输入的AudioUnit连接到  MixerUnit上。最终将 MixerUnit 连接到 RemoteIO 这个 AudioUnit 的 OutputElement，将声音发送到耳机的扬声器中(如果直接发送到手机的 扬声器中就会出现啸叫)，这样就将 AUGraph 整体地建立起来了</p>
<p><img src="/2021/08/03/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/01.png" alt="01"></p>
<p><a target="_blank" rel="noopener" href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40007875">Audio Session Programming Guide</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingGuide_iOS/ConstructingAudioUnitApps/ConstructingAudioUnitApps.html#//apple_ref/doc/uid/TP40009492-CH16-SW1">Audio Unit Hosting Guide for iOS</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zhanxiaokai/iOS-AudioRecorder">音频采集代码 AudioRecorder</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zhanxiaokai?tab=repositories">音视频进阶开发指南源码</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/07/30/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%87%8D%E6%8E%92/" rel="prev" title="二进制重排">
                  <i class="fa fa-chevron-left"></i> 二进制重排
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/08/06/Core-Audio/" rel="next" title="Core Audio">
                  Core Audio <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">daxun</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/local-search.js"></script>















  








  

  

</body>
</html>
